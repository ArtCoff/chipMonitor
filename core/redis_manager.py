import redis
import logging
import json
import time
import threading
from typing import Optional, Dict, Any, List
from collections import defaultdict, deque


class RedisManager:
    """Redisè¿æ¥å’Œæ“ä½œç®¡ç†å™¨"""

    def __init__(self, redis_url: str = None):
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„URL
        if redis_url is None:
            try:
                from config.redis_config import redis_config

                self.redis_url = getattr(
                    redis_config, "url", "redis://localhost:6379/0"
                )
            except (ImportError, AttributeError):
                self.redis_url = "redis://localhost:6379/0"
        else:
            self.redis_url = redis_url

        self.logger = logging.getLogger("RedisManager")

        # ğŸ”¥ åŒæ­¥Rediså®¢æˆ·ç«¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self._sync_client: Optional[redis.Redis] = None
        self._connection_pool: Optional[redis.ConnectionPool] = None

        # è¿æ¥çŠ¶æ€
        self._connected = False
        self._connection_attempts = 0
        self._max_retry_attempts = 3

        # ğŸ”¥ çº¿ç¨‹å®‰å…¨é”ï¼ˆç”¨äºè¿æ¥çŠ¶æ€æ£€æŸ¥ï¼‰
        self._lock = threading.RLock()

    def connect(self) -> bool:
        """å»ºç«‹Redisè¿æ¥ - çº¿ç¨‹æ± ä¼˜åŒ–ç‰ˆæœ¬"""
        with self._lock:
            try:
                self.logger.info(f"æ­£åœ¨è¿æ¥Redis: {self.redis_url}")

                # ğŸ”¥ åˆ›å»ºè¿æ¥æ± ï¼Œæ”¯æŒå¤šçº¿ç¨‹å¹¶å‘
                self._connection_pool = redis.ConnectionPool.from_url(
                    self.redis_url,
                    decode_responses=True,
                    max_connections=20,  # ğŸ”¥ æ”¯æŒçº¿ç¨‹æ± å¹¶å‘
                    socket_connect_timeout=3,
                    socket_timeout=5,
                    socket_keepalive=True,
                    socket_keepalive_options={},
                    retry_on_timeout=True,
                    health_check_interval=30,
                )

                # åˆ›å»ºRediså®¢æˆ·ç«¯
                self._sync_client = redis.Redis(connection_pool=self._connection_pool)

                # æµ‹è¯•è¿æ¥
                result = self._sync_client.ping()
                if result:
                    self._connected = True
                    self._connection_attempts = 0
                    self.logger.info(f"âœ… Redisè¿æ¥æˆåŠŸ: {self.redis_url} (è¿æ¥æ± : 20)")
                    return True
                else:
                    raise Exception("Redis ping å¤±è´¥")

            except Exception as e:
                self._connected = False
                self._connection_attempts += 1

                self.logger.error(
                    f"âŒ Redisè¿æ¥å¤±è´¥ ({self._connection_attempts}/{self._max_retry_attempts}): {e}"
                )
                return False

    def get_client(self) -> Optional[redis.Redis]:
        """è·å–Rediså®¢æˆ·ç«¯ - çº¿ç¨‹å®‰å…¨"""
        # ğŸ”¥ æ— éœ€åŠ é”ï¼ŒRedisè¿æ¥æ± è‡ªåŠ¨å¤„ç†çº¿ç¨‹å®‰å…¨
        if self._connected and self._sync_client:
            return self._sync_client
        return None

    def is_connected(self) -> bool:
        """æ£€æŸ¥è¿æ¥çŠ¶æ€ - çº¿ç¨‹å®‰å…¨"""
        if not self._sync_client:
            return False

        try:
            # ğŸ”¥ è½»é‡çº§è¿æ¥æ£€æŸ¥
            self._sync_client.ping()
            return True
        except Exception:
            with self._lock:
                self._connected = False
            return False

    def reconnect(self) -> bool:
        """é‡è¿Redis - çº¿ç¨‹å®‰å…¨"""
        with self._lock:
            try:
                self.logger.info("å°è¯•é‡è¿Redis...")
                self.close()
                return self.connect()
            except Exception as e:
                self.logger.error(f"Redisé‡è¿å¤±è´¥: {e}")
                return False

    def close(self):
        """å…³é—­è¿æ¥ - çº¿ç¨‹å®‰å…¨"""
        with self._lock:
            try:
                if self._connection_pool:
                    self._connection_pool.disconnect()

                self._sync_client = None
                self._connection_pool = None
                self._connected = False

                self.logger.info("Redisè¿æ¥å·²å…³é—­")
            except Exception as e:
                self.logger.error(f"å…³é—­Redisè¿æ¥å¤±è´¥: {e}")

    def get_info(self) -> Dict[str, Any]:
        """è·å–è¿æ¥ä¿¡æ¯ - çº¿ç¨‹å®‰å…¨"""
        with self._lock:
            return {
                "redis_url": self.redis_url,
                "connected": self._connected,
                "connection_attempts": self._connection_attempts,
                "max_retry_attempts": self._max_retry_attempts,
                "client_available": self._sync_client is not None,
                "pool_available": self._connection_pool is not None,
            }


class RedisDataBuffer:
    """Redisæ•°æ®ç¼“å†²å™¨ - çº¿ç¨‹å®‰å…¨ + æ‰¹é‡ä¼˜åŒ–"""

    def __init__(self, redis_manager: RedisManager):
        self.redis_manager = redis_manager
        self.logger = logging.getLogger("RedisDataBuffer")
        self._data_channel_enum = None
        self._buffer_strategies = None

        # ğŸ”¥ æ‰¹é‡ç¼“å†²æ”¯æŒï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self._batch_queues = defaultdict(lambda: deque())
        self._batch_locks = defaultdict(lambda: threading.Lock())
        self._last_flush_time = defaultdict(lambda: time.time())

    @property
    def buffer_strategies(self):
        """å»¶è¿Ÿåˆå§‹åŒ–ç¼“å†²ç­–ç•¥"""
        if self._buffer_strategies is None:
            try:
                from .data_bus import DataChannel

                self._data_channel_enum = DataChannel

                self._buffer_strategies = {
                    DataChannel.TELEMETRY_DATA: {
                        "redis_type": "stream",
                        "key": "telemetry_stream",
                        "max_length": 10000,
                        "batch_size": 100,  # ğŸ”¥ ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
                        "flush_interval": 5,  # ğŸ”¥ ä¼˜åŒ–åˆ·æ–°é—´éš”
                        "ttl": 3600,
                    },
                    DataChannel.ALERTS: {
                        "redis_type": "list",
                        "key": "alerts_queue",
                        "max_length": 1000,
                        "batch_size": 20,  # ğŸ”¥ ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
                        "flush_interval": 2,  # ğŸ”¥ ä¼˜åŒ–åˆ·æ–°é—´éš”
                        "ttl": 86400,
                    },
                    DataChannel.ERRORS: {
                        "redis_type": "list",
                        "key": "errors_queue",
                        "max_length": 1000,
                        "batch_size": 20,
                        "flush_interval": 2,
                        "ttl": 86400,
                    },
                    DataChannel.DEVICE_EVENTS: {
                        "redis_type": "list",
                        "key": "device_events_queue",
                        "max_length": 2000,
                        "batch_size": 50,
                        "flush_interval": 3,
                        "ttl": 86400,
                    },
                }
            except ImportError as e:
                self.logger.warning(f"æ— æ³•å¯¼å…¥DataChannel: {e}")
                self._buffer_strategies = {}

        return self._buffer_strategies

    def buffer_message(self, message, enable_batching: bool = True) -> bool:
        """ç¼“å†²æ¶ˆæ¯åˆ°Redis - æ”¯æŒæ‰¹é‡å’Œå•æ¡"""
        client = self.redis_manager.get_client()
        if not client:
            self.logger.debug("Redisæœªè¿æ¥ï¼Œè·³è¿‡ç¼“å†²")
            return False

        try:
            strategy = self.buffer_strategies.get(message.channel)
            if not strategy:
                self.logger.debug(f"é¢‘é“ {message.channel.value} æœªé…ç½®ç¼“å†²ç­–ç•¥")
                return True

            # ğŸ”¥ æ”¯æŒæ‰¹é‡ç¼“å†²ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è°ƒç”¨æ—¶æ¨èï¼‰
            if enable_batching:
                return self._batch_buffer_message(client, message, strategy)
            else:
                return self._single_buffer_message(client, message, strategy)

        except Exception as e:
            self.logger.error(f"ç¼“å†²æ¶ˆæ¯å¤±è´¥: {e}")
            return False

    def _batch_buffer_message(
        self, client: redis.Redis, message, strategy: dict
    ) -> bool:
        """æ‰¹é‡ç¼“å†²æ¶ˆæ¯ - çº¿ç¨‹å®‰å…¨"""
        try:
            channel_key = message.channel.value

            # ğŸ”¥ çº¿ç¨‹å®‰å…¨çš„æ‰¹é‡æ“ä½œ
            with self._batch_locks[channel_key]:
                # æ·»åŠ åˆ°æ‰¹é‡é˜Ÿåˆ—
                self._batch_queues[channel_key].append(message)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
                should_flush = (
                    len(self._batch_queues[channel_key]) >= strategy["batch_size"]
                    or (time.time() - self._last_flush_time[channel_key])
                    >= strategy["flush_interval"]
                )

                if should_flush:
                    return self._flush_batch_messages(client, message.channel, strategy)

            return True

        except Exception as e:
            self.logger.error(f"æ‰¹é‡ç¼“å†²å¤±è´¥: {e}")
            return False

    def _single_buffer_message(
        self, client: redis.Redis, message, strategy: dict
    ) -> bool:
        """å•æ¡æ¶ˆæ¯ç¼“å†² - ç«‹å³å†™å…¥"""
        try:
            # å‡†å¤‡æ¶ˆæ¯æ•°æ®
            message_data = {
                "channel": message.channel.value,
                "source": message.source,
                "data": (
                    json.dumps(message.data, ensure_ascii=False)
                    if not isinstance(message.data, str)
                    else message.data
                ),
                "timestamp": message.timestamp,
                "device_id": message.device_id or "",
            }

            # æ ¹æ®ç­–ç•¥é€‰æ‹©Redisæ•°æ®ç»“æ„
            if strategy["redis_type"] == "stream":
                return self._buffer_to_stream(client, strategy, message_data)
            elif strategy["redis_type"] == "list":
                return self._buffer_to_list(client, strategy, message_data)

        except Exception as e:
            self.logger.error(f"å•æ¡ç¼“å†²å¤±è´¥: {e}")
            return False

    def _flush_batch_messages(
        self, client: redis.Redis, channel, strategy: dict
    ) -> bool:
        """åˆ·æ–°æ‰¹é‡æ¶ˆæ¯ - ä½¿ç”¨Pipeline"""
        try:
            channel_key = channel.value

            # è·å–å¾…åˆ·æ–°çš„æ¶ˆæ¯
            messages = list(self._batch_queues[channel_key])
            self._batch_queues[channel_key].clear()
            self._last_flush_time[channel_key] = time.time()

            if not messages:
                return True

            # ğŸ”¥ ä½¿ç”¨Pipelineæ‰¹é‡æ“ä½œï¼Œæé«˜æ€§èƒ½
            pipe = client.pipeline()

            for message in messages:
                message_data = {
                    "channel": message.channel.value,
                    "source": message.source,
                    "data": (
                        json.dumps(message.data, ensure_ascii=False)
                        if not isinstance(message.data, str)
                        else message.data
                    ),
                    "timestamp": message.timestamp,
                    "device_id": message.device_id or "",
                }

                if strategy["redis_type"] == "stream":
                    pipe.xadd(
                        strategy["key"],
                        message_data,
                        maxlen=strategy["max_length"],
                        approximate=True,
                    )
                elif strategy["redis_type"] == "list":
                    pipe.lpush(
                        strategy["key"], json.dumps(message_data, ensure_ascii=False)
                    )

            # é™åˆ¶é•¿åº¦ï¼ˆå¯¹äºlistç±»å‹ï¼‰
            if strategy["redis_type"] == "list":
                pipe.ltrim(strategy["key"], 0, strategy["max_length"] - 1)

            # ğŸ”¥ æ‰§è¡Œæ‰¹é‡æ“ä½œ
            results = pipe.execute()

            success_count = sum(1 for r in results if r)
            self.logger.debug(
                f"æ‰¹é‡åˆ·æ–°: {channel_key} ({success_count}/{len(messages)}æ¡)"
            )

            return success_count > 0

        except Exception as e:
            self.logger.error(f"æ‰¹é‡åˆ·æ–°å¤±è´¥: {e}")
            return False

    def _buffer_to_stream(
        self, client: redis.Redis, strategy: dict, message_data: dict
    ) -> bool:
        """ç¼“å†²åˆ°Redis Stream"""
        try:
            result = client.xadd(
                strategy["key"],
                message_data,
                maxlen=strategy["max_length"],
                approximate=True,
            )
            return bool(result)
        except Exception as e:
            self.logger.error(f"Streamç¼“å†²å¤±è´¥: {e}")
            return False

    def _buffer_to_list(
        self, client: redis.Redis, strategy: dict, message_data: dict
    ) -> bool:
        """ç¼“å†²åˆ°Redis List"""
        try:
            pipe = client.pipeline()
            pipe.lpush(strategy["key"], json.dumps(message_data, ensure_ascii=False))
            pipe.ltrim(strategy["key"], 0, strategy["max_length"] - 1)

            if strategy.get("ttl"):
                pipe.expire(strategy["key"], strategy["ttl"])

            results = pipe.execute()
            return bool(results[0])  # LPUSHç»“æœ
        except Exception as e:
            self.logger.error(f"Listç¼“å†²å¤±è´¥: {e}")
            return False

    # ğŸ”¥ æ–°å¢ï¼šå¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ‰¹é‡é˜Ÿåˆ—
    def force_flush_all_batches(self) -> Dict[str, int]:
        """å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ‰¹é‡é˜Ÿåˆ—"""
        flush_results = {}
        client = self.redis_manager.get_client()

        if not client:
            return {"error": "Redisæœªè¿æ¥"}

        try:
            for channel in self.buffer_strategies.keys():
                channel_key = channel.value
                strategy = self.buffer_strategies[channel]

                with self._batch_locks[channel_key]:
                    if self._batch_queues[channel_key]:
                        success = self._flush_batch_messages(client, channel, strategy)
                        flush_results[channel_key] = {
                            "success": success,
                            "messages_flushed": len(self._batch_queues[channel_key]),
                        }

        except Exception as e:
            flush_results["error"] = str(e)

        return flush_results

    # ä¿æŒå…¶ä»–ç°æœ‰æ–¹æ³•ä¸å˜...
    def get_buffered_count(self, channel) -> int:
        """è·å–ç¼“å†²åŒºä¸­çš„æ¶ˆæ¯æ•°é‡"""
        client = self.redis_manager.get_client()
        if not client:
            return 0

        try:
            strategy = self.buffer_strategies.get(channel)
            if not strategy:
                return 0

            if strategy["redis_type"] == "stream":
                return client.xlen(strategy["key"])
            elif strategy["redis_type"] == "list":
                return client.llen(strategy["key"])

        except Exception as e:
            self.logger.error(f"è·å–ç¼“å†²æ•°é‡å¤±è´¥: {e}")

        return 0

    def clear_buffer(self, channel) -> bool:
        """æ¸…ç©ºæŒ‡å®šé¢‘é“çš„ç¼“å†²åŒº"""
        client = self.redis_manager.get_client()
        if not client:
            return False

        try:
            strategy = self.buffer_strategies.get(channel)
            if not strategy:
                return True

            # ğŸ”¥ åŒæ—¶æ¸…ç©ºå†…å­˜æ‰¹é‡é˜Ÿåˆ—
            channel_key = channel.value
            with self._batch_locks[channel_key]:
                self._batch_queues[channel_key].clear()

            # æ¸…ç©ºRedisä¸­çš„æ•°æ®
            result = client.delete(strategy["key"])
            self.logger.info(f"âœ… å·²æ¸…ç©ºé¢‘é“ {channel.value} çš„ç¼“å†²åŒº")
            return True

        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç©ºç¼“å†²åŒºå¤±è´¥: {e}")
            return False

    def get_buffer_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å†²ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "redis_connected": self.redis_manager.is_connected(),
            "buffer_counts": {},
            "batch_queue_sizes": {},
            "total_buffered": 0,
            "total_queued": 0,
        }

        if not self.redis_manager.is_connected():
            return stats

        try:
            for channel in self.buffer_strategies.keys():
                # Redisä¸­çš„æ•°é‡
                redis_count = self.get_buffered_count(channel)
                stats["buffer_counts"][channel.value] = redis_count
                stats["total_buffered"] += redis_count

                # å†…å­˜é˜Ÿåˆ—ä¸­çš„æ•°é‡
                channel_key = channel.value
                queue_size = len(self._batch_queues[channel_key])
                stats["batch_queue_sizes"][channel_key] = queue_size
                stats["total_queued"] += queue_size

        except Exception as e:
            stats["error"] = str(e)

        return stats


# ğŸ”¥ å…¨å±€Redisç®¡ç†å™¨å®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
redis_manager = RedisManager()
redis_buffer = RedisDataBuffer(redis_manager)
