import time
import logging
from typing import Optional, Any
from PySide6.QtCore import QTimer, Qt, Slot
from .data_bus import DataBus, DataChannel, DataMessage
from .redis_manager import redis_manager, redis_buffer
from .thread_pool import thread_pool, TaskType, TaskPriority


class EnhancedDataBus(DataBus):
    """å¢å¼ºç‰ˆæ•°æ®æ€»çº¿ - é›†æˆRedisç¼“å†² + çº¿ç¨‹æ± åè°ƒ"""

    def __init__(self, enable_redis_buffer: bool = True):
        super().__init__()
        self.redis_buffer_enabled = enable_redis_buffer
        self.logger = logging.getLogger("EnhancedDataBus")

        # ğŸ”¥ çº¿ç¨‹æ± é›†æˆ
        self.thread_pool = thread_pool

        # ğŸ”¥ è¿æ¥çº¿ç¨‹æ± ä¿¡å· - ä½¿ç”¨æ­£ç¡®çš„ä¿¡å·åç§°
        self.thread_pool.task_completed.connect(
            self._on_redis_task_completed, Qt.QueuedConnection
        )
        self.thread_pool.task_failed.connect(
            self._on_redis_task_failed, Qt.QueuedConnection
        )

        # åˆå§‹åŒ–Redisè¿æ¥
        if self.redis_buffer_enabled:
            self._init_redis_connection()

        # ğŸ”¥ ç¼“å†²ç»Ÿè®¡ - ç®€åŒ–ç‰ˆæœ¬
        self._buffer_stats = {
            "buffered_messages": 0,
            "buffer_errors": 0,
            "redis_connected": False,
            "pending_redis_tasks": 0,
        }

        # ğŸ”¥ å®šæ—¶ç»Ÿè®¡å’Œæ‰¹é‡åˆ·æ–°
        self._setup_timers()

    def _init_redis_connection(self):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        try:
            if redis_manager.connect():
                self._buffer_stats["redis_connected"] = True
                self.logger.info("âœ… Enhanced DataBus Redisç¼“å†²å·²å¯ç”¨")
            else:
                self.redis_buffer_enabled = False
                self.logger.warning("âš ï¸ Redisè¿æ¥å¤±è´¥ï¼Œç¦ç”¨ç¼“å†²åŠŸèƒ½")
        except Exception as e:
            self.redis_buffer_enabled = False
            self.logger.error(f"âŒ Redisåˆå§‹åŒ–å¤±è´¥: {e}")

    def _setup_timers(self):
        """è®¾ç½®å®šæ—¶å™¨ - æ‰¹é‡åˆ·æ–°å’Œç»Ÿè®¡æ›´æ–°"""
        # ğŸ”¥ æ‰¹é‡åˆ·æ–°å®šæ—¶å™¨ - å¼ºåˆ¶åˆ·æ–°æ‰¹é‡é˜Ÿåˆ—
        self.flush_timer = QTimer()
        self.flush_timer.timeout.connect(self._force_flush_batches)
        self.flush_timer.start(30000)  # 30ç§’å¼ºåˆ¶åˆ·æ–°ä¸€æ¬¡

        # ğŸ”¥ è¿æ¥çŠ¶æ€æ£€æŸ¥å®šæ—¶å™¨
        self.health_timer = QTimer()
        self.health_timer.timeout.connect(self._health_check)
        self.health_timer.start(60000)  # 60ç§’æ£€æŸ¥ä¸€æ¬¡Redisè¿æ¥

    def publish(
        self,
        channel: DataChannel,
        source: str,
        data: Any,
        device_id: Optional[str] = None,
    ) -> bool:
        """å‘å¸ƒæ¶ˆæ¯ - DataBuså®æ—¶ + Rediså¼‚æ­¥ç¼“å†²"""

        # 1. ğŸ”¥ ç«‹å³å‘å¸ƒåˆ°å†…å­˜DataBusï¼ˆä¿è¯å®æ—¶æ€§ï¼‰
        success = super().publish(channel, source, data, device_id)

        # 2. ğŸ”¥ å¼‚æ­¥æäº¤Redisç¼“å†²ä»»åŠ¡ï¼ˆä¿è¯æŒä¹…åŒ–ï¼Œä¸é˜»å¡UIï¼‰
        if success and self.redis_buffer_enabled:
            self._submit_redis_buffer_task(channel, source, data, device_id)

        return success

    def _submit_redis_buffer_task(
        self, channel: DataChannel, source: str, data: Any, device_id: Optional[str]
    ):
        """æäº¤Redisç¼“å†²ä»»åŠ¡åˆ°çº¿ç¨‹æ±  - ä¿®å¤å‚æ•°ä¼ é€’"""
        try:
            message = DataMessage(
                channel=channel, source=source, data=data, device_id=device_id
            )

            # ğŸ”¥ ä¿®å¤ï¼šæ­£ç¡®ä¼ é€’å‚æ•°ç»™çº¿ç¨‹æ± 
            task_id = self.thread_pool.submit(
                TaskType.DATA_PROCESSING,
                self._redis_buffer_worker,
                message,
                task_id=f"redis_{channel.value}_{int(time.time()*1000000)}",
                priority=TaskPriority.NORMAL,
                timeout=10.0,
                max_retries=1,  # ğŸ”¥ å…è®¸1æ¬¡é‡è¯•
            )

            if task_id:
                self._buffer_stats["pending_redis_tasks"] += 1
                self.logger.debug(f"Redisç¼“å†²ä»»åŠ¡å·²æäº¤: {task_id}")
            else:
                self._buffer_stats["buffer_errors"] += 1

        except Exception as e:
            self._buffer_stats["buffer_errors"] += 1
            self.logger.error(f"æäº¤Redisä»»åŠ¡å¤±è´¥: {e}")

    def _redis_buffer_worker(self, message: DataMessage) -> dict:
        """Redisç¼“å†²å·¥ä½œå‡½æ•° - åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ"""
        start_time = time.time()
        result = {
            "success": False,
            "channel": message.channel.value,
            "device_id": message.device_id,
            "execution_time": 0,
            "error": None,
        }

        try:
            # ğŸ”¥ åœ¨å­çº¿ç¨‹ä¸­æ‰§è¡ŒRedisç¼“å†²æ“ä½œï¼Œå¯ç”¨æ‰¹é‡æ¨¡å¼
            success = redis_buffer.buffer_message(message, enable_batching=True)

            result.update(
                {
                    "success": success,
                    "execution_time": (time.time() - start_time) * 1000,  # æ¯«ç§’
                }
            )

            return result

        except Exception as e:
            result.update(
                {
                    "success": False,
                    "execution_time": (time.time() - start_time) * 1000,
                    "error": str(e),
                }
            )
            return result

    @Slot(str, object)
    def _on_redis_task_completed(self, task_id: str, result: dict):
        """Redisä»»åŠ¡å®Œæˆå¤„ç† - ä¸»çº¿ç¨‹å›è°ƒ"""
        try:
            # ğŸ”¥ åªå¤„ç†Redisç›¸å…³ä»»åŠ¡
            if not task_id.startswith("redis_"):
                return

            self._buffer_stats["pending_redis_tasks"] = max(
                0, self._buffer_stats["pending_redis_tasks"] - 1
            )

            if result.get("success"):
                self._buffer_stats["buffered_messages"] += 1
                execution_time = result.get("execution_time", 0)
                self.logger.debug(
                    f"Redisç¼“å†²æˆåŠŸ: {result.get('channel')} ({execution_time:.1f}ms)"
                )
            else:
                self._buffer_stats["buffer_errors"] += 1
                error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                self.logger.error(f"Redisç¼“å†²å¤±è´¥: {error_msg}")

        except Exception as e:
            self.logger.error(f"å¤„ç†Redisä»»åŠ¡å®Œæˆå›è°ƒå¤±è´¥: {e}")

    @Slot(str, str)
    def _on_redis_task_failed(self, task_id: str, error: str):
        """Redisä»»åŠ¡å¤±è´¥å¤„ç† - ä¸»çº¿ç¨‹å›è°ƒ"""
        try:
            if not task_id.startswith("redis_"):
                return

            self._buffer_stats["pending_redis_tasks"] = max(
                0, self._buffer_stats["pending_redis_tasks"] - 1
            )
            self._buffer_stats["buffer_errors"] += 1

            self.logger.error(f"Redisç¼“å†²ä»»åŠ¡å¤±è´¥ {task_id}: {error}")

        except Exception as e:
            self.logger.error(f"å¤„ç†Redisä»»åŠ¡å¤±è´¥å›è°ƒå¤±è´¥: {e}")

    @Slot()
    def _force_flush_batches(self):
        """å®šæ—¶å¼ºåˆ¶åˆ·æ–°æ‰¹é‡é˜Ÿåˆ— - ç¡®ä¿æ•°æ®æœ€ç»ˆå†™å…¥Redis"""
        if not self.redis_buffer_enabled:
            return

        try:
            # ğŸ”¥ ä½¿ç”¨çº¿ç¨‹æ± å¼‚æ­¥æ‰§è¡Œæ‰¹é‡åˆ·æ–°ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
            task_id = self.thread_pool.submit(
                task_type=TaskType.BATCH_PROCESSING,
                func=redis_buffer.force_flush_all_batches,
                task_id=f"flush_batches_{int(time.time())}",
                priority=TaskPriority.NORMAL,
                timeout=30.0,
            )

            if task_id:
                self.logger.debug(f"æ‰¹é‡åˆ·æ–°ä»»åŠ¡å·²æäº¤: {task_id}")

        except Exception as e:
            self.logger.error(f"æäº¤æ‰¹é‡åˆ·æ–°ä»»åŠ¡å¤±è´¥: {e}")

    @Slot()
    def _health_check(self):
        """Redisè¿æ¥å¥åº·æ£€æŸ¥"""
        if not self.redis_buffer_enabled:
            return

        try:
            # ğŸ”¥ å¿«é€Ÿæ£€æŸ¥Redisè¿æ¥çŠ¶æ€
            is_connected = redis_manager.is_connected()
            self._buffer_stats["redis_connected"] = is_connected

            if not is_connected:
                self.logger.warning("âš ï¸ Redisè¿æ¥æ–­å¼€ï¼Œå°è¯•é‡è¿...")

                # ğŸ”¥ å¼‚æ­¥é‡è¿ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
                task_id = self.thread_pool.submit(
                    task_type=TaskType.DATA_PROCESSING,
                    func=redis_manager.reconnect,
                    task_id=f"redis_reconnect_{int(time.time())}",
                    priority=TaskPriority.HIGH,
                    timeout=10.0,
                )

                if task_id:
                    self.logger.info("Redisé‡è¿ä»»åŠ¡å·²æäº¤")

        except Exception as e:
            self.logger.error(f"Rediså¥åº·æ£€æŸ¥å¤±è´¥: {e}")

    def get_buffer_stats(self) -> dict:
        """è·å–ç¼“å†²ç»Ÿè®¡ä¿¡æ¯ - å¢å¼ºç‰ˆæœ¬"""
        # ğŸ”¥ è·å–åŸºç¡€DataBusç»Ÿè®¡
        stats = super().get_stats()

        # ğŸ”¥ æ·»åŠ Redisç¼“å†²ç»Ÿè®¡
        if self.redis_buffer_enabled:
            try:
                # è·å–Redisç¼“å†²åŒºç»Ÿè®¡
                redis_stats = redis_buffer.get_buffer_stats()

                # åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
                enhanced_stats = self._buffer_stats.copy()
                enhanced_stats.update(
                    {
                        "redis_manager_info": redis_manager.get_info(),
                        "buffer_efficiency": self._calculate_buffer_efficiency(),
                    }
                )

                stats.update(
                    {
                        "redis_buffer": enhanced_stats,
                        "redis_detailed": redis_stats,
                    }
                )

            except Exception as e:
                stats["redis_buffer_error"] = str(e)

        # ğŸ”¥ æ·»åŠ çº¿ç¨‹æ± ç»Ÿè®¡
        try:
            thread_stats = self.thread_pool.get_metrics()
            stats["thread_pool"] = {
                "active_workers": thread_stats.get("active_workers", 0),
                "queue_size": thread_stats.get("queue_size", 0),
                "total_completed": thread_stats.get("total_completed", 0),
                "total_failed": thread_stats.get("total_failed", 0),
            }
        except Exception as e:
            stats["thread_pool_error"] = str(e)

        return stats

    def _calculate_buffer_efficiency(self) -> float:
        """è®¡ç®—ç¼“å†²æ•ˆç‡"""
        try:
            total_attempts = (
                self._buffer_stats["buffered_messages"]
                + self._buffer_stats["buffer_errors"]
            )
            if total_attempts == 0:
                return 100.0

            return (self._buffer_stats["buffered_messages"] / total_attempts) * 100.0

        except Exception:
            return 0.0

    def force_flush_buffers(self) -> dict:
        """å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰ç¼“å†²åŒº - ç”¨äºè°ƒè¯•å’Œå…³é—­å‰æ¸…ç†"""
        if not self.redis_buffer_enabled:
            return {"error": "Redisç¼“å†²æœªå¯ç”¨"}

        try:
            # ğŸ”¥ åŒæ­¥æ‰§è¡Œæ‰¹é‡åˆ·æ–°ï¼ˆç”¨äºå…³é—­å‰çš„æœ€ç»ˆæ¸…ç†ï¼‰
            flush_results = redis_buffer.force_flush_all_batches()

            # è·å–Redisä¸­çš„æ•°æ®ç»Ÿè®¡
            buffer_counts = {}
            for channel in DataChannel:
                count = redis_buffer.get_buffered_count(channel)
                if count > 0:
                    buffer_counts[channel.value] = count

            flush_results.update({"final_buffer_counts": buffer_counts})

            self.logger.info(f"å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒºå®Œæˆ: {flush_results}")
            return flush_results

        except Exception as e:
            error_msg = f"å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒºå¤±è´¥: {e}"
            self.logger.error(error_msg)
            return {"error": error_msg}

    def clear_all_buffers(self) -> dict:
        """æ¸…ç©ºæ‰€æœ‰ç¼“å†²åŒº - åŒ…æ‹¬å†…å­˜é˜Ÿåˆ—å’ŒRedis"""
        if not self.redis_buffer_enabled:
            return {"error": "Redisç¼“å†²æœªå¯ç”¨"}

        try:
            clear_results = {}

            # ğŸ”¥ é€ä¸ªæ¸…ç©ºæ¯ä¸ªé¢‘é“çš„ç¼“å†²åŒº
            for channel in DataChannel:
                success = redis_buffer.clear_buffer(channel)
                clear_results[channel.value] = "success" if success else "failed"

            self.logger.info(f"æ¸…ç©ºæ‰€æœ‰ç¼“å†²åŒº: {clear_results}")
            return clear_results

        except Exception as e:
            error_msg = f"æ¸…ç©ºç¼“å†²åŒºå¤±è´¥: {e}"
            self.logger.error(error_msg)
            return {"error": error_msg}

    def reconnect_redis(self) -> bool:
        """é‡æ–°è¿æ¥Redis - æä¾›ç»™å¤–éƒ¨è°ƒç”¨"""
        try:
            if redis_manager.reconnect():
                self.redis_buffer_enabled = True
                self._buffer_stats["redis_connected"] = True
                self.logger.info("âœ… Redisé‡è¿æˆåŠŸ")
                return True
            else:
                self.redis_buffer_enabled = False
                self._buffer_stats["redis_connected"] = False
                self.logger.error("âŒ Redisé‡è¿å¤±è´¥")
                return False
        except Exception as e:
            self.logger.error(f"Redisé‡è¿å¼‚å¸¸: {e}")
            return False

    def shutdown(self):
        """ä¼˜é›…å…³é—­ - æ¸…ç†èµ„æº"""
        try:
            self.logger.info("æ­£åœ¨å…³é—­Enhanced DataBus...")

            # ğŸ”¥ åœæ­¢å®šæ—¶å™¨
            if hasattr(self, "flush_timer"):
                self.flush_timer.stop()
            if hasattr(self, "health_timer"):
                self.health_timer.stop()

            # ğŸ”¥ å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰å¾…å¤„ç†çš„æ‰¹é‡æ•°æ®
            if self.redis_buffer_enabled:
                self.force_flush_buffers()

            # ğŸ”¥ ç­‰å¾…Redisä»»åŠ¡å®Œæˆ
            pending_tasks = self._buffer_stats.get("pending_redis_tasks", 0)
            if pending_tasks > 0:
                self.logger.info(f"ç­‰å¾… {pending_tasks} ä¸ªRedisä»»åŠ¡å®Œæˆ...")
                # ç»™ä¸€äº›æ—¶é—´è®©ä»»åŠ¡å®Œæˆ
                import time

                time.sleep(2)

            self.logger.info("Enhanced DataBuså·²å…³é—­")

        except Exception as e:
            self.logger.error(f"å…³é—­Enhanced DataBusæ—¶å‘ç”Ÿé”™è¯¯: {e}")


# ğŸ”¥ å…¨å±€å¢å¼ºæ•°æ®æ€»çº¿å®ä¾‹
enhanced_data_bus = EnhancedDataBus()
