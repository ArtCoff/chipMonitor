# core/database_manager.py
import json
import logging
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple

import psycopg2
from psycopg2.pool import ThreadedConnectionPool
from psycopg2.extras import RealDictCursor
from PySide6.QtCore import QObject, QTimer, Signal, Slot

from config.database_config import database_config, DatabaseConfig, DatabaseStats
from .thread_pool import thread_pool, TaskType, TaskPriority


class DatabaseManager(QObject):
    """ç®€åŒ–çš„æ•°æ®åº“ç®¡ç†å™¨ - ç¡®ä¿ç»„ä»¶åè°ƒ"""

    # ğŸ”¥ ä¿¡å·å®šä¹‰ - ä¸æ§åˆ¶é¢æ¿åŒ¹é…
    connection_changed = Signal(bool, str)  # è¿æ¥çŠ¶æ€å˜åŒ– (åŒ¹é…æ§åˆ¶é¢æ¿)
    stats_updated = Signal(object)  # ç»Ÿè®¡ä¿¡æ¯æ›´æ–° (DatabaseStatså¯¹è±¡)
    migration_completed = Signal(dict)  # è¿ç§»å®Œæˆ
    migration_failed = Signal(str)  # è¿ç§»å¤±è´¥

    def __init__(self):
        super().__init__()
        self.logger = logging.getLogger("DatabaseManager")

        # ğŸ”¥ è¿æ¥æ± å’ŒçŠ¶æ€
        self._connection_pool: Optional[ThreadedConnectionPool] = None
        self._connected = False
        self._lock = threading.RLock()

        # ğŸ”¥ ç»Ÿè®¡ä¿¡æ¯ç¼“å­˜
        self._cached_stats = DatabaseStats()
        self._last_stats_update = 0

        # ğŸ”¥ è¿ç§»æ§åˆ¶
        self._migration_running = False

        # ğŸ”¥ è®¾ç½®å®šæ—¶å™¨
        self._setup_timers()

    def _setup_timers(self):
        """è®¾ç½®å®šæ—¶å™¨"""
        # ç»Ÿè®¡æ›´æ–°å®šæ—¶å™¨
        self.stats_timer = QTimer()
        self.stats_timer.timeout.connect(self._update_stats_async)
        self.stats_timer.start(30000)  # 30ç§’æ›´æ–°ç»Ÿè®¡

        # è¿æ¥å¥åº·æ£€æŸ¥å®šæ—¶å™¨
        self.health_timer = QTimer()
        self.health_timer.timeout.connect(self._health_check)
        self.health_timer.start(60000)  # 1åˆ†é’Ÿæ£€æŸ¥è¿æ¥

        # æ•°æ®è¿ç§»å®šæ—¶å™¨ (å¦‚æœéœ€è¦)
        self.migration_timer = QTimer()
        self.migration_timer.timeout.connect(self._scheduled_migration)
        # é»˜è®¤ä¸å¯åŠ¨ï¼Œå¯é€šè¿‡é…ç½®å¯ç”¨

    def test_connection(
        self, config: Optional[DatabaseConfig] = None
    ) -> Tuple[bool, str]:
        """æµ‹è¯•æ•°æ®åº“è¿æ¥ - ä¸æ§åˆ¶é¢æ¿æ¥å£åŒ¹é…"""
        test_config = config or database_config

        try:
            self.logger.info(f"æµ‹è¯•æ•°æ®åº“è¿æ¥: {test_config.host}:{test_config.port}")

            # åˆ›å»ºæµ‹è¯•è¿æ¥
            test_conn = psycopg2.connect(**test_config.get_connection_params())

            # æµ‹è¯•æŸ¥è¯¢
            with test_conn.cursor() as cursor:
                cursor.execute("SELECT version();")
                version = cursor.fetchone()[0]

            test_conn.close()

            # æå–ç‰ˆæœ¬å·
            version_info = version.split()[0] + " " + version.split()[1]
            success_msg = f"è¿æ¥æˆåŠŸ: {version_info}"
            self.logger.info(success_msg)
            return True, success_msg

        except Exception as e:
            error_msg = f"è¿æ¥å¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg

    def connect(self, config: Optional[DatabaseConfig] = None) -> bool:
        """è¿æ¥æ•°æ®åº“ - ä¸æ§åˆ¶é¢æ¿æ¥å£åŒ¹é…"""
        with self._lock:
            try:
                connect_config = config or database_config

                # å…³é—­ç°æœ‰è¿æ¥
                self.disconnect()

                # ğŸ”¥ åˆ›å»ºè¿æ¥æ± 
                self._connection_pool = ThreadedConnectionPool(
                    minconn=connect_config.min_connections,
                    maxconn=connect_config.max_connections,
                    **connect_config.get_connection_params(),
                )

                # ğŸ”¥ æµ‹è¯•è¿æ¥å¹¶åˆå§‹åŒ–è¡¨ç»“æ„
                conn = self._connection_pool.getconn()
                try:
                    with conn.cursor() as cursor:
                        cursor.execute("SELECT 1;")
                        cursor.fetchone()

                    # åˆå§‹åŒ–è¡¨ç»“æ„
                    self._init_tables(conn)

                finally:
                    self._connection_pool.putconn(conn)

                self._connected = True
                self.connection_changed.emit(True, "æ•°æ®åº“è¿æ¥æˆåŠŸ")

                self.logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
                return True

            except Exception as e:
                self._connected = False
                error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}"
                self.connection_changed.emit(False, error_msg)
                self.logger.error(error_msg)
                return False

    def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥ - ä¸æ§åˆ¶é¢æ¿æ¥å£åŒ¹é…"""
        with self._lock:
            try:
                if self._connection_pool:
                    self._connection_pool.closeall()
                    self._connection_pool = None

                self._connected = False
                self.connection_changed.emit(False, "æ•°æ®åº“è¿æ¥å·²æ–­å¼€")
                self.logger.info("æ•°æ®åº“è¿æ¥å·²æ–­å¼€")

            except Exception as e:
                self.logger.error(f"æ–­å¼€æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")

    def _init_tables(self, conn):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„ - ç®€åŒ–ç‰ˆæœ¬"""
        try:
            with conn.cursor() as cursor:
                # ğŸ”¥ é¥æµ‹æ•°æ®è¡¨
                cursor.execute(
                    """
                    CREATE TABLE IF NOT EXISTS telemetry_data (
                        id BIGSERIAL PRIMARY KEY,
                        device_id VARCHAR(100) NOT NULL,
                        channel VARCHAR(50) NOT NULL,
                        source VARCHAR(100) NOT NULL,
                        temperature DECIMAL(10,3),
                        pressure DECIMAL(10,3),
                        rf_power DECIMAL(10,3),
                        endpoint DECIMAL(10,3),
                        humidity DECIMAL(10,3),
                        vibration DECIMAL(10,3),
                        data_timestamp TIMESTAMPTZ NOT NULL,
                        created_at TIMESTAMPTZ DEFAULT NOW()
                    );
                    CREATE INDEX IF NOT EXISTS idx_telemetry_device_time 
                    ON telemetry_data(device_id, data_timestamp DESC);
                    CREATE INDEX IF NOT EXISTS idx_telemetry_created 
                    ON telemetry_data(created_at DESC);
                """
                )

                # ğŸ”¥ å‘Šè­¦æ•°æ®è¡¨
                cursor.execute(
                    """
                    CREATE TABLE IF NOT EXISTS alerts (
                        id BIGSERIAL PRIMARY KEY,
                        device_id VARCHAR(100),
                        alert_type VARCHAR(100) NOT NULL,
                        severity VARCHAR(20) NOT NULL,
                        message TEXT NOT NULL,
                        alert_data JSONB,
                        data_timestamp TIMESTAMPTZ NOT NULL,
                        created_at TIMESTAMPTZ DEFAULT NOW(),
                        resolved_at TIMESTAMPTZ
                    );
                    CREATE INDEX IF NOT EXISTS idx_alerts_device_time 
                    ON alerts(device_id, data_timestamp DESC);
                    CREATE INDEX IF NOT EXISTS idx_alerts_unresolved 
                    ON alerts(resolved_at) WHERE resolved_at IS NULL;
                """
                )

                # ğŸ”¥ è®¾å¤‡äº‹ä»¶è¡¨
                cursor.execute(
                    """
                    CREATE TABLE IF NOT EXISTS device_events (
                        id BIGSERIAL PRIMARY KEY,
                        device_id VARCHAR(100) NOT NULL,
                        event_type VARCHAR(100) NOT NULL,
                        event_data JSONB,
                        severity VARCHAR(20) DEFAULT 'info',
                        data_timestamp TIMESTAMPTZ NOT NULL,
                        created_at TIMESTAMPTZ DEFAULT NOW()
                    );
                    CREATE INDEX IF NOT EXISTS idx_events_device_time 
                    ON device_events(device_id, data_timestamp DESC);
                    CREATE INDEX IF NOT EXISTS idx_events_type 
                    ON device_events(event_type);
                """
                )

                conn.commit()
                self.logger.info("âœ… æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            conn.rollback()
            self.logger.error(f"åˆå§‹åŒ–æ•°æ®åº“è¡¨å¤±è´¥: {e}")
            raise

    def get_stats(self) -> DatabaseStats:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯ - ä¸æ§åˆ¶é¢æ¿æ¥å£åŒ¹é…"""
        # ğŸ”¥ ä½¿ç”¨ç¼“å­˜é¿å…é¢‘ç¹æŸ¥è¯¢
        current_time = time.time()
        if current_time - self._last_stats_update < 10:  # 10ç§’ç¼“å­˜
            return self._cached_stats

        stats = DatabaseStats()
        stats.connected = self._connected
        stats.last_check_time = current_time

        if not self._connected or not self._connection_pool:
            self._cached_stats = stats
            return stats

        try:
            conn = self._connection_pool.getconn()
            try:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    # è·å–å„è¡¨è®°å½•æ•°
                    cursor.execute("SELECT COUNT(*) as count FROM telemetry_data")
                    stats.telemetry_count = cursor.fetchone()["count"]

                    cursor.execute("SELECT COUNT(*) as count FROM alerts")
                    stats.alerts_count = cursor.fetchone()["count"]

                    cursor.execute("SELECT COUNT(*) as count FROM device_events")
                    stats.events_count = cursor.fetchone()["count"]

                    stats.total_records = (
                        stats.telemetry_count + stats.alerts_count + stats.events_count
                    )

                    # è·å–æ•°æ®åº“å¤§å°
                    cursor.execute(
                        "SELECT pg_database_size(current_database()) as size_bytes"
                    )
                    size_bytes = cursor.fetchone()["size_bytes"]
                    stats.database_size_mb = size_bytes / 1024 / 1024

            finally:
                self._connection_pool.putconn(conn)

            self._cached_stats = stats
            self._last_stats_update = current_time

        except Exception as e:
            self.logger.error(f"è·å–æ•°æ®åº“ç»Ÿè®¡å¤±è´¥: {e}")

        return stats

    @Slot()
    def _update_stats_async(self):
        """å¼‚æ­¥æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        if not self._connected:
            return

        try:
            # ğŸ”¥ ä½¿ç”¨çº¿ç¨‹æ± å¼‚æ­¥è·å–ç»Ÿè®¡
            task_id = thread_pool.submit(
                task_type=TaskType.DATA_PROCESSING,
                func=self._get_stats_worker,
                task_id=f"stats_{int(time.time())}",
                priority=TaskPriority.LOW,
                timeout=30.0,
            )

        except Exception as e:
            self.logger.error(f"æäº¤ç»Ÿè®¡ä»»åŠ¡å¤±è´¥: {e}")

    def _get_stats_worker(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯çš„å·¥ä½œå‡½æ•°"""
        try:
            stats = self.get_stats()

            # ğŸ”¥ å‘å°„ä¿¡å·åˆ°ä¸»çº¿ç¨‹
            self.stats_updated.emit(stats)

            return {
                "success": True,
                "total_records": stats.total_records,
                "database_size_mb": stats.database_size_mb,
            }

        except Exception as e:
            self.logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    @Slot()
    def _health_check(self):
        """æ•°æ®åº“è¿æ¥å¥åº·æ£€æŸ¥"""
        if not self._connection_pool:
            return

        try:
            conn = self._connection_pool.getconn()
            try:
                with conn.cursor() as cursor:
                    cursor.execute("SELECT 1;")
                    cursor.fetchone()

                # è¿æ¥æ­£å¸¸ï¼Œå¦‚æœä¹‹å‰æ–­å¼€åˆ™å‘é€æ¢å¤ä¿¡å·
                if not self._connected:
                    self._connected = True
                    self.connection_changed.emit(True, "æ•°æ®åº“è¿æ¥æ¢å¤")

            finally:
                self._connection_pool.putconn(conn)

        except Exception as e:
            # è¿æ¥å¼‚å¸¸ï¼Œå¦‚æœä¹‹å‰æ­£å¸¸åˆ™å‘é€æ–­å¼€ä¿¡å·
            if self._connected:
                self._connected = False
                error_msg = f"æ•°æ®åº“è¿æ¥æ£€æŸ¥å¤±è´¥: {e}"
                self.connection_changed.emit(False, error_msg)
                self.logger.error(error_msg)

    @Slot()
    def _scheduled_migration(self):
        """å®šæ—¶æ•°æ®è¿ç§» - ç®€åŒ–ç‰ˆæœ¬"""
        if not self._connected or self._migration_running:
            return

        try:
            # ğŸ”¥ ä½¿ç”¨çº¿ç¨‹æ± å¼‚æ­¥æ‰§è¡Œè¿ç§»
            task_id = thread_pool.submit(
                task_type=TaskType.BATCH_PROCESSING,
                func=self._migration_worker,
                task_id=f"migration_{int(time.time())}",
                priority=TaskPriority.LOW,
                timeout=300.0,
            )

            if task_id:
                self._migration_running = True
                self.logger.debug(f"æ•°æ®è¿ç§»ä»»åŠ¡å·²æäº¤: {task_id}")

        except Exception as e:
            self.logger.error(f"æäº¤æ•°æ®è¿ç§»ä»»åŠ¡å¤±è´¥: {e}")

    def _migration_worker(self) -> dict:
        """æ•°æ®è¿ç§»å·¥ä½œå‡½æ•° - ä»Redisè¿ç§»åˆ°PostgreSQL"""
        start_time = time.time()
        result = {
            "total_processed": 0,
            "total_success": 0,
            "total_failed": 0,
            "execution_time": 0,
            "errors": [],
        }

        try:
            # ğŸ”¥ è¿™é‡Œå¯ä»¥æ·»åŠ ä»Redisè·å–æ•°æ®å¹¶è¿ç§»åˆ°PostgreSQLçš„é€»è¾‘
            # ç”±äºredis_bufferå¯èƒ½ä¸å­˜åœ¨ï¼Œå…ˆè·³è¿‡å…·ä½“å®ç°

            # ç¤ºä¾‹ä»£ç ç»“æ„ï¼š
            # if hasattr(self, 'redis_buffer'):
            #     messages = self.redis_buffer.get_pending_messages()
            #     result = self._process_migration_messages(messages)

            result["execution_time"] = (time.time() - start_time) * 1000

            if result["total_processed"] > 0:
                self.logger.info(
                    f"æ•°æ®è¿ç§»å®Œæˆ: {result['total_success']}/{result['total_processed']} æ¡"
                )
                self.migration_completed.emit(result)

            return result

        except Exception as e:
            error_msg = f"æ•°æ®è¿ç§»å¤±è´¥: {e}"
            result["errors"].append(error_msg)
            self.logger.error(error_msg)
            self.migration_failed.emit(error_msg)
            return result

        finally:
            self._migration_running = False

    def is_connected(self) -> bool:
        """æ£€æŸ¥è¿æ¥çŠ¶æ€"""
        return self._connected

    def execute_query(
        self, query: str, params: tuple = None, fetch_all: bool = True
    ) -> List[Dict]:
        """æ‰§è¡ŒæŸ¥è¯¢ - æä¾›ç»™å…¶ä»–ç»„ä»¶ä½¿ç”¨"""
        if not self._connected or not self._connection_pool:
            raise Exception("æ•°æ®åº“æœªè¿æ¥")

        try:
            conn = self._connection_pool.getconn()
            try:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    cursor.execute(query, params)

                    if fetch_all:
                        return [dict(row) for row in cursor.fetchall()]
                    else:
                        result = cursor.fetchone()
                        return [dict(result)] if result else []

            finally:
                self._connection_pool.putconn(conn)

        except Exception as e:
            self.logger.error(f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥: {e}")
            raise

    def execute_insert(self, table: str, data: Dict[str, Any]) -> bool:
        """æ‰§è¡Œæ’å…¥æ“ä½œ"""
        if not self._connected or not self._connection_pool:
            return False

        try:
            conn = self._connection_pool.getconn()
            try:
                with conn.cursor() as cursor:
                    columns = list(data.keys())
                    values = list(data.values())
                    placeholders = ", ".join(["%s"] * len(values))

                    query = f"INSERT INTO {table} ({', '.join(columns)}) VALUES ({placeholders})"
                    cursor.execute(query, values)

                conn.commit()
                return True

            finally:
                self._connection_pool.putconn(conn)

        except Exception as e:
            self.logger.error(f"æ’å…¥æ•°æ®å¤±è´¥: {e}")
            return False

    def manual_migration(self) -> dict:
        """æ‰‹åŠ¨è§¦å‘æ•°æ®è¿ç§»"""
        if self._migration_running:
            return {"error": "è¿ç§»ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­"}

        try:
            task_id = thread_pool.submit(
                task_type=TaskType.BATCH_PROCESSING,
                func=self._migration_worker,
                task_id=f"manual_migration_{int(time.time())}",
                priority=TaskPriority.NORMAL,
                timeout=300.0,
            )

            if task_id:
                return {"success": True, "task_id": task_id}
            else:
                return {"error": "ä»»åŠ¡æäº¤å¤±è´¥"}

        except Exception as e:
            return {"error": str(e)}

    def enable_migration(self, interval_seconds: int = 300):
        """å¯ç”¨å®šæ—¶è¿ç§»"""
        try:
            if not self.migration_timer.isActive():
                self.migration_timer.start(interval_seconds * 1000)
                self.logger.info(f"æ•°æ®è¿ç§»å·²å¯ç”¨ï¼Œé—´éš”: {interval_seconds}ç§’")
                return True
        except Exception as e:
            self.logger.error(f"å¯ç”¨æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return False

    def disable_migration(self):
        """ç¦ç”¨å®šæ—¶è¿ç§»"""
        try:
            if self.migration_timer.isActive():
                self.migration_timer.stop()
                self.logger.info("æ•°æ®è¿ç§»å·²ç¦ç”¨")
                return True
        except Exception as e:
            self.logger.error(f"ç¦ç”¨æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return False

    def shutdown(self):
        """å…³é—­æ•°æ®åº“ç®¡ç†å™¨"""
        try:
            self.logger.info("æ­£åœ¨å…³é—­æ•°æ®åº“ç®¡ç†å™¨...")

            # åœæ­¢å®šæ—¶å™¨
            self.stats_timer.stop()
            self.health_timer.stop()
            self.migration_timer.stop()

            # ç­‰å¾…è¿ç§»ä»»åŠ¡å®Œæˆ
            if self._migration_running:
                self.logger.info("ç­‰å¾…æ•°æ®è¿ç§»ä»»åŠ¡å®Œæˆ...")
                time.sleep(2)

            # æ–­å¼€æ•°æ®åº“è¿æ¥
            self.disconnect()

            self.logger.info("æ•°æ®åº“ç®¡ç†å™¨å·²å…³é—­")

        except Exception as e:
            self.logger.error(f"å…³é—­æ•°æ®åº“ç®¡ç†å™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")


# å…¨å±€æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
db_manager = DatabaseManager()
