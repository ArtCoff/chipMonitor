import time
import logging
import threading
from typing import Dict, List, Any
from collections import deque, defaultdict
from PySide6.QtCore import QObject, QTimer, Signal, Slot

from core.data_bus import get_data_bus, DataChannel, DataMessage
from core.database_manager import get_db_manager
from core.thread_pool import get_thread_pool, TaskType, TaskPriority


class DatabasePersistenceService(QObject):
    """æ•°æ®åº“æŒä¹…åŒ–æœåŠ¡ - ç‹¬ç«‹æœåŠ¡ï¼Œè®¢é˜…DataBuså¹¶æ‰¹é‡å†™å…¥æ•°æ®åº“"""

    # æœåŠ¡çŠ¶æ€ä¿¡å·
    service_started = Signal()
    service_stopped = Signal()
    batch_processed = Signal(str, dict)  # (channel, result)
    batch_failed = Signal(str, str)  # (channel, error)
    stats_updated = Signal(dict)

    def __init__(self):
        super().__init__()
        self.logger = logging.getLogger("DatabasePersistenceService")
        self.data_bus = get_data_bus()
        self.db_manager = get_db_manager()
        self.thread_pool = get_thread_pool()
        # ğŸ”¥ æœåŠ¡çŠ¶æ€
        self._running = False
        self._subscribed = False

        # ğŸ”¥ æ‰¹é‡ç­–ç•¥é…ç½®
        self.batch_strategies = {
            DataChannel.TELEMETRY_DATA: {
                "batch_size": 50,
                "flush_interval": 10,  # ç§’
                "enable_persistence": True,
            },
            DataChannel.ALERTS: {
                "batch_size": 20,
                "flush_interval": 5,
                "enable_persistence": True,
            },
            DataChannel.DEVICE_EVENTS: {
                "batch_size": 30,
                "flush_interval": 8,
                "enable_persistence": True,
            },
            DataChannel.ERRORS: {
                "batch_size": 10,
                "flush_interval": 3,
                "enable_persistence": True,
            },
        }

        # ğŸ”¥ æ‰¹é‡é˜Ÿåˆ—ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self.batch_queues = defaultdict(lambda: deque())
        self.batch_locks = defaultdict(lambda: threading.Lock())
        self.last_flush_time = defaultdict(lambda: time.time())

        # ğŸ”¥ ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "service_uptime": 0,
            "messages_received": 0,
            "messages_batched": 0,
            "messages_persisted": 0,
            "batch_flushes": 0,
            "batch_errors": 0,
            "channels_active": 0,
        }
        self._start_time = 0

        # å®šæ—¶å™¨
        self.flush_timer = QTimer()
        self.stats_timer = QTimer()

        self.logger.info("æ•°æ®åº“æŒä¹…åŒ–æœåŠ¡å·²åˆå§‹åŒ–")

    def start(self) -> bool:
        """å¯åŠ¨æŒä¹…åŒ–æœåŠ¡"""
        try:
            if self._running:
                self.logger.warning("æŒä¹…åŒ–æœåŠ¡å·²åœ¨è¿è¡Œä¸­")
                return True

            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            if not self.db_manager.is_connected():
                self.logger.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨æŒä¹…åŒ–æœåŠ¡")
                return False

            # è®¢é˜…æ‰€æœ‰æ•°æ®é¢‘é“
            self._subscribe_channels()

            # å¯åŠ¨å®šæ—¶å™¨
            self.flush_timer.timeout.connect(self._scheduled_flush)
            self.flush_timer.start(30000)  # 30ç§’å¼ºåˆ¶åˆ·æ–°

            self.stats_timer.timeout.connect(self._update_stats)
            self.stats_timer.start(10000)  # 10ç§’æ›´æ–°ç»Ÿè®¡

            self._running = True
            self._start_time = time.time()

            self.service_started.emit()
            self.logger.info("æ•°æ®åº“æŒä¹…åŒ–æœåŠ¡å·²å¯åŠ¨")
            return True

        except Exception as e:
            self.logger.error(f"å¯åŠ¨æŒä¹…åŒ–æœåŠ¡å¤±è´¥: {e}")
            return False

    def stop(self) -> bool:
        """åœæ­¢æŒä¹…åŒ–æœåŠ¡"""
        try:
            if not self._running:
                self.logger.warning("æŒä¹…åŒ–æœåŠ¡æœªåœ¨è¿è¡Œ")
                return True

            self.logger.info("æ­£åœ¨åœæ­¢æ•°æ®åº“æŒä¹…åŒ–æœåŠ¡...")

            # ğŸ”¥ åœæ­¢å®šæ—¶å™¨
            self.flush_timer.stop()
            self.stats_timer.stop()

            # ğŸ”¥ å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰å¾…å¤„ç†æ•°æ®
            self._flush_all_batches_sync()

            # ğŸ”¥ å–æ¶ˆè®¢é˜…
            self._unsubscribe_channels()

            self._running = False

            self.service_stopped.emit()
            self.logger.info("æ•°æ®åº“æŒä¹…åŒ–æœåŠ¡å·²åœæ­¢")
            return True

        except Exception as e:
            self.logger.error(f"åœæ­¢æŒä¹…åŒ–æœåŠ¡å¤±è´¥: {e}")
            return False

    def _subscribe_channels(self):
        """è®¢é˜…æ‰€æœ‰æ•°æ®é¢‘é“"""
        try:
            for channel in DataChannel:
                success = self.data_bus.subscribe(channel, self._on_message_received)
                if success:
                    self.logger.debug(f"å·²è®¢é˜…é¢‘é“: {channel.value}")
                else:
                    self.logger.error(f"è®¢é˜…é¢‘é“å¤±è´¥: {channel.value}")

            self._subscribed = True

        except Exception as e:
            self.logger.error(f"è®¢é˜…é¢‘é“å¤±è´¥: {e}")

    def _unsubscribe_channels(self):
        """å–æ¶ˆè®¢é˜…æ‰€æœ‰é¢‘é“"""
        try:
            for channel in DataChannel:
                self.data_bus.unsubscribe(channel, self._on_message_received)
                self.logger.debug(f"å·²å–æ¶ˆè®¢é˜…: {channel.value}")

            self._subscribed = False

        except Exception as e:
            self.logger.error(f"å–æ¶ˆè®¢é˜…å¤±è´¥: {e}")

    @Slot()
    def _on_message_received(self, message: DataMessage):
        """æ¥æ”¶åˆ°æ•°æ®æ€»çº¿æ¶ˆæ¯"""
        try:
            if not self._running:
                return

            # æ£€æŸ¥æ˜¯å¦å¯ç”¨æŒä¹…åŒ–
            strategy = self.batch_strategies.get(message.channel)
            if not strategy or not strategy.get("enable_persistence", True):
                return

            # ğŸ”¥ æ·»åŠ åˆ°æ‰¹é‡é˜Ÿåˆ—
            self._add_to_batch(message, strategy)

            self.stats["messages_received"] += 1

        except Exception as e:
            self.logger.error(f"å¤„ç†æ¥æ”¶æ¶ˆæ¯å¤±è´¥: {e}")

    def _add_to_batch(self, message: DataMessage, strategy: dict):
        """æ·»åŠ æ¶ˆæ¯åˆ°æ‰¹é‡é˜Ÿåˆ—"""
        channel_key = message.channel.value

        with self.batch_locks[channel_key]:
            self.batch_queues[channel_key].append(message)
            self.stats["messages_batched"] += 1

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
            should_flush = (
                len(self.batch_queues[channel_key]) >= strategy["batch_size"]
                or (time.time() - self.last_flush_time[channel_key])
                >= strategy["flush_interval"]
            )

            if should_flush:
                self._flush_batch_async(message.channel, strategy)

    def _flush_batch_async(self, channel: DataChannel, strategy: dict):
        """å¼‚æ­¥åˆ·æ–°æ‰¹é‡æ•°æ®"""
        try:
            submit_kwargs = {
                "task_type": TaskType.BATCH_PROCESSING,
                "func": self._batch_worker,
                "task_id": f"db_batch_{channel.value}_{int(time.time())}",
                "priority": TaskPriority.NORMAL,
                "timeout": 30.0,
            }
            task_id = self.thread_pool.submit(
                TaskType.BATCH_PROCESSING,
                self._batch_worker,
                channel,
                strategy,
                task_id=f"db_batch_{channel.value}_{int(time.time())}",
                priority=TaskPriority.NORMAL,
                timeout=30.0,
            )

            if task_id:
                self.logger.debug(f"æ•°æ®åº“æ‰¹é‡ä»»åŠ¡å·²æäº¤: {task_id}")

        except Exception as e:
            self.logger.error(f"æäº¤æ‰¹é‡ä»»åŠ¡å¤±è´¥: {e}")
            self.stats["batch_errors"] += 1

    def _batch_worker(self, channel: DataChannel, strategy: dict) -> dict:
        """æ‰¹é‡å†™å…¥å·¥ä½œå‡½æ•°"""
        start_time = time.time()
        result = {"success": False, "processed": 0, "errors": []}

        try:
            channel_key = channel.value

            # è·å–å¾…å¤„ç†æ¶ˆæ¯
            with self.batch_locks[channel_key]:
                messages = list(self.batch_queues[channel_key])
                self.batch_queues[channel_key].clear()
                self.last_flush_time[channel_key] = time.time()

            if not messages:
                return {"success": True, "processed": 0}

            # ğŸ”¥ æ ¹æ®é¢‘é“ç±»å‹è°ƒç”¨æ•°æ®åº“ç®¡ç†å™¨çš„æ‰¹é‡æ’å…¥
            if self.db_manager.is_connected():
                if channel == DataChannel.TELEMETRY_DATA:
                    result = self.db_manager.batch_insert_telemetry(messages)
                elif channel == DataChannel.ALERTS:
                    result = self.db_manager.batch_insert_alerts(messages)
                elif channel == DataChannel.DEVICE_EVENTS:
                    result = self.db_manager.batch_insert_events(messages)
                elif channel == DataChannel.ERRORS:
                    result = self.db_manager.batch_insert_errors(messages)

                if result["success"]:
                    self.stats["messages_persisted"] += result.get("processed", 0)
                    self.stats["batch_flushes"] += 1
                    self.batch_processed.emit(channel.value, result)
                else:
                    self.stats["batch_errors"] += 1
                    self.batch_failed.emit(channel.value, str(result.get("errors")))
            else:
                result = {"success": False, "processed": 0, "errors": ["æ•°æ®åº“æœªè¿æ¥"]}
                self.stats["batch_errors"] += 1
                self.batch_failed.emit(channel.value, "æ•°æ®åº“æœªè¿æ¥")

            result["execution_time"] = (time.time() - start_time) * 1000

            if result["success"]:
                self.logger.info(
                    f"æ•°æ®åº“æ‰¹é‡å†™å…¥å®Œæˆ: {channel.value} "
                    f"({result['processed']}æ¡, {result['execution_time']:.1f}ms)"
                )

            return result

        except Exception as e:
            error_msg = f"æ‰¹é‡å†™å…¥å¤±è´¥: {e}"
            result["errors"].append(error_msg)
            self.logger.error(error_msg)
            self.stats["batch_errors"] += 1
            self.batch_failed.emit(channel.value, error_msg)
            return result

    @Slot()
    def _scheduled_flush(self):
        """å®šæ—¶å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ‰¹é‡é˜Ÿåˆ—"""
        try:
            if not self._running:
                return

            flushed_channels = []

            for channel, strategy in self.batch_strategies.items():
                channel_key = channel.value

                with self.batch_locks[channel_key]:
                    queue_size = len(self.batch_queues[channel_key])

                if queue_size > 0:
                    self._flush_batch_async(channel, strategy)
                    flushed_channels.append(f"{channel.value}({queue_size})")

            if flushed_channels:
                self.logger.info(f"å®šæ—¶åˆ·æ–°æ‰¹é‡é˜Ÿåˆ—: {', '.join(flushed_channels)}")

        except Exception as e:
            self.logger.error(f"å®šæ—¶åˆ·æ–°å¤±è´¥: {e}")

    def _flush_all_batches_sync(self):
        """åŒæ­¥åˆ·æ–°æ‰€æœ‰æ‰¹é‡é˜Ÿåˆ—ï¼ˆç”¨äºåœæ­¢æœåŠ¡æ—¶ï¼‰"""
        try:
            for channel, strategy in self.batch_strategies.items():
                channel_key = channel.value

                with self.batch_locks[channel_key]:
                    messages = list(self.batch_queues[channel_key])
                    self.batch_queues[channel_key].clear()

                if messages and self.db_manager.is_connected():
                    if channel == DataChannel.TELEMETRY_DATA:
                        self.db_manager.batch_insert_telemetry(messages)
                    elif channel == DataChannel.ALERTS:
                        self.db_manager.batch_insert_alerts(messages)
                    elif channel == DataChannel.DEVICE_EVENTS:
                        self.db_manager.batch_insert_events(messages)
                    elif channel == DataChannel.ERRORS:
                        self.db_manager.batch_insert_errors(messages)

                    self.logger.info(
                        f"åŒæ­¥åˆ·æ–° {channel.value}: {len(messages)} æ¡è®°å½•"
                    )

        except Exception as e:
            self.logger.error(f"åŒæ­¥åˆ·æ–°å¤±è´¥: {e}")

    @Slot()
    def _update_stats(self):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if self._running:
                self.stats["service_uptime"] = time.time() - self._start_time
                self.stats["channels_active"] = len(
                    [ch for ch, queue in self.batch_queues.items() if queue]
                )

                self.stats_updated.emit(self.stats.copy())

        except Exception as e:
            self.logger.error(f"æ›´æ–°ç»Ÿè®¡å¤±è´¥: {e}")

    def get_service_stats(self) -> dict:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()

        # æ·»åŠ é˜Ÿåˆ—çŠ¶æ€
        queue_stats = {}
        for channel_key, queue in self.batch_queues.items():
            with self.batch_locks[channel_key]:
                queue_stats[channel_key] = len(queue)

        stats.update(
            {
                "running": self._running,
                "subscribed": self._subscribed,
                "queue_sizes": queue_stats,
                "database_connected": self.db_manager.is_connected(),
                "batch_strategies": {
                    ch.value: strategy for ch, strategy in self.batch_strategies.items()
                },
            }
        )

        return stats

    def manual_flush_channel(self, channel: DataChannel) -> bool:
        """æ‰‹åŠ¨åˆ·æ–°æŒ‡å®šé¢‘é“"""
        try:
            if not self._running:
                return False

            strategy = self.batch_strategies.get(channel)
            if not strategy:
                return False

            self._flush_batch_async(channel, strategy)
            return True

        except Exception as e:
            self.logger.error(f"æ‰‹åŠ¨åˆ·æ–°é¢‘é“å¤±è´¥: {e}")
            return False

    def update_batch_strategy(
        self,
        channel: DataChannel,
        batch_size: int = None,
        flush_interval: int = None,
        enable_persistence: bool = None,
    ):
        """æ›´æ–°æ‰¹é‡ç­–ç•¥"""
        try:
            if channel not in self.batch_strategies:
                return False

            strategy = self.batch_strategies[channel]

            if batch_size is not None:
                strategy["batch_size"] = max(1, batch_size)
            if flush_interval is not None:
                strategy["flush_interval"] = max(1, flush_interval)
            if enable_persistence is not None:
                strategy["enable_persistence"] = enable_persistence

            self.logger.info(f"å·²æ›´æ–° {channel.value} æ‰¹é‡ç­–ç•¥: {strategy}")
            return True

        except Exception as e:
            self.logger.error(f"æ›´æ–°æ‰¹é‡ç­–ç•¥å¤±è´¥: {e}")
            return False


# ğŸ”¥ å…¨å±€æ•°æ®åº“æŒä¹…åŒ–æœåŠ¡å®ä¾‹
database_persistence_service = DatabasePersistenceService()
